# ğŸ’³ Credit Card Fraud Detection â€” End-to-End Machine Learning System

Fraud detection is a highly **imbalanced binary classification problem**, where fraudulent transactions represent less than **0.18%** of all records.  
This project provides a **full production-ready fraud detection pipeline** built using:

- Classical Machine Learning models
- Ensemble Learning
- Deep Learning with Focal Loss
- Advanced resampling techniques
- Automated evaluation & model comparison
- Streamlit web interface for training and prediction

---

# ğŸ“ Project Structure

```
.
â”œâ”€â”€ data
â”‚Â Â  â””â”€â”€ processed
â”‚Â Â      â”œâ”€â”€ raw
â”‚Â Â      â”‚Â Â  â””â”€â”€ creditcard.csv
â”‚Â Â      â”œâ”€â”€ test.csv
â”‚Â Â      â””â”€â”€ train.csv
â”œâ”€â”€ LICENSE
â”œâ”€â”€ models
â”‚Â Â  â””â”€â”€ saved_models
â”‚Â Â      â”œâ”€â”€ focal_nn_model.pt
â”‚Â Â      â”œâ”€â”€ logistic_model.pkl
â”‚Â Â      â”œâ”€â”€ random_forest_model.pkl
â”‚Â Â      â”œâ”€â”€ voting_classifier_model.pkl
â”‚Â Â      â””â”€â”€ xgboost_model.pkl
â”œâ”€â”€ notebooks
â”‚Â Â  â”œâ”€â”€ 01_EDA.ipynb
â”‚Â Â  â””â”€â”€ 02_model_baseline.ipynb
â”œâ”€â”€ page_predict.py
â”œâ”€â”€ page_train.py
â”œâ”€â”€ __pycache__
â”‚Â Â  â”œâ”€â”€ page_predict.cpython-310.pyc
â”‚Â Â  â””â”€â”€ page_train.cpython-310.pyc
â”œâ”€â”€ README.md
â”œâ”€â”€ reports
â”‚Â Â  â”œâ”€â”€ best_model.txt
â”‚Â Â  â”œâ”€â”€ Logistic Regression_optimal_report.txt
â”‚Â Â  â”œâ”€â”€ Logistic Regression_report.txt
â”‚Â Â  â”œâ”€â”€ model_comparison.csv
â”‚Â Â  â”œâ”€â”€ model_comparison_heatmap.png
â”‚Â Â  â”œâ”€â”€ Neural_Network_optimal_report.txt
â”‚Â Â  â”œâ”€â”€ Neural_Network_report.txt
â”‚Â Â  â”œâ”€â”€ plots
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ logistic_regression_cm.png
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ logistic_regression_hist.png
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ logistic_regression_pr.png
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ logistic_regression_roc.png
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ random_forest_cm.png
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ random_forest_hist.png
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ random_forest_pr.png
â”‚Â Â  â”‚Â Â  â””â”€â”€ random_forest_roc.png
â”‚Â Â  â”œâ”€â”€ Random Forest_optimal_report.txt
â”‚Â Â  â”œâ”€â”€ Random Forest_report.txt
â”‚Â Â  â”œâ”€â”€ Voting Classifier_optimal_report.txt
â”‚Â Â  â”œâ”€â”€ Voting Classifier_report.txt
â”‚Â Â  â”œâ”€â”€ XGBoost_optimal_report.txt
â”‚Â Â  â””â”€â”€ XGBoost_report.txt
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ src
â”‚Â Â  â”œâ”€â”€ config
â”‚Â Â  â”‚Â Â  â””â”€â”€ settings.yaml
â”‚Â Â  â”œâ”€â”€ data
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ load_data.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __pycache__
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ load_data.cpython-310.pyc
â”‚Â Â  â”‚Â Â  â””â”€â”€ split.py
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”œâ”€â”€ main.py
â”‚Â Â  â”œâ”€â”€ models
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ foacl
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ focal_loss.py
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ fraud_nn.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __pycache__
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ focal_loss.cpython-310.pyc
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ fraud_nn.cpython-310.pyc
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ random_forest.cpython-310.pyc
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ voting_classifier.cpython-310.pyc
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ xgboost_model.cpython-310.pyc
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ random_forest.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ voting_classifier.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ xgboost_model.py
â”‚Â Â  â”œâ”€â”€ pipelines
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ evaluate.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ focal
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ train_focal.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ model_selector.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __pycache__
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ evaluate.cpython-310.pyc
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ model_selector.cpython-310.pyc
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ trainer.cpython-310.pyc
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ train_focal.cpython-310.pyc
â”‚Â Â  â”‚Â Â  â””â”€â”€ trainer.py
â”‚Â Â  â”œâ”€â”€ __pycache__
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __init__.cpython-310.pyc
â”‚Â Â  â”‚Â Â  â””â”€â”€ page_train.cpython-310.pyc
â”‚Â Â  â””â”€â”€ utils
â”‚Â Â      â”œâ”€â”€ metrics_extended.py
â”‚Â Â      â”œâ”€â”€ plot_all.py
â”‚Â Â      â”œâ”€â”€ preprocess.py
â”‚Â Â      â”œâ”€â”€ __pycache__
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ metrics_extended.cpython-310.pyc
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ plot_all.cpython-310.pyc
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ plot_curves.cpython-310.pyc
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ preprocess.cpython-310.pyc
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ resampling.cpython-310.pyc
â”‚Â Â      â”‚Â Â  â””â”€â”€ save_load.cpython-310.pyc
â”‚Â Â      â”œâ”€â”€ resampling.py
â”‚Â Â      â””â”€â”€ save_load.py
â””â”€â”€ streamlit_app.py
```

---

# ğŸ”§ Installation

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/ahmedkhalidak/fraud-detection.git
cd fraud-detection
```

### 2ï¸âƒ£ Create a Conda environment

```
conda create -n fraud-env python=3.10 -y
conda activate fraud-env
```

### 3ï¸âƒ£ Install dependencies

```
pip install -r requirements.txt
```

# ğŸ“¥ Dataset Setup

Download the dataset from Kaggle:

ğŸ”— https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud

- Place creditcard.csv inside:

```
data/raw/creditcard.csv
```

- Then generate train/test split:

```
python src/data/split.py
```

# ğŸ” Exploratory Data Analysis

### Key observations:

- No missing values

- PCA-transformed features `V1â€“V28`

- Highly imbalanced dataset:
  - Class 0 (Normal): `284,315` samples
  - Class 1 (Fraud): `492` samples

# ğŸ§± Baseline Models

| Model               | Notes                         |
| ------------------- | ----------------------------- |
| Logistic Regression | Strong recall, weak precision |

# ğŸ”¥ Deep Learning with Focal Loss

Standard BCE struggles with extreme imbalance.
Focal Loss helps focus on minority (fraud) samples :

```
loss = Î± * (1 - pt)^Î³ * BCE
```

# ğŸ“Š Model Evaluation

ROC Curves

Logistic Regression

Random Forest

XGBoost

Voting Classifier

Focal Neural Network

# ğŸ”¥ Model Comparison (Heatmap)

![ Model Comparison ](reports/model_comparison_heatmap.png)

Includes:

- F1-score (fraud class)

- Recall

- Precision

- Macro F1

- PR-AUC

- Optimal threshold metrics

# ğŸ§ª Streamlit Web Application

- A full interactive interface to:

- Train models

- Apply SMOTE, undersampling, SMOTE+ENN

- Visualize ROC, PR, confusion matrix

- Run model comparison

- Save & load models

- Predict single transactions or batch CSV

- Run the app:

```
streamlit run streamlit_app.py
```

![alt text](<Screenshot from 2025-12-07 03-39-42.png>)

![alt text](<Screenshot from 2025-12-07 03-40-10.png>)

# ğŸ† Best Model Selection

### Automatically selects the best-performing model based on:

- F1-score (fraud class)

- PR-AUC

- Recall weighting

### And The Best Model -> Random Forest with best Threshold

Written to:

```
reports/best_model.txt
```

# ğŸ§  System Architecture

```
flowchart TD

A[Raw Dataset] --> B[Preprocessing & Scaling]
B --> C[Train/Test Split]
C --> D[Baseline Models]
C --> E[Resampling Techniques]
C --> F[Focal Loss Neural Network]

D --> G[Evaluation]
E --> G
F --> G

G --> H[Model Comparison Engine]
H --> I[Best Model Selector]
I --> J[Streamlit App]
```

# ğŸ“¦ Saved Models

Exported models stored in:

```
models/saved_models/

```
